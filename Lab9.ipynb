{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab9.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "SthYlmXzUFVP",
        "colab_type": "code",
        "outputId": "a865c1d1-8df6-40fe-8863-7121a1626ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install gym"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 28kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x58b86000 @  0x7fc94772e2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-0.4.1\n",
            "Collecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 13.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n",
            "Installing collected packages: pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torchvision-0.2.1\n",
            "Collecting gym\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/22/4ff09745ade385ffe707fb5f053548f0f6a6e7d5e98a2b9d6c07f5b931a7/gym-0.10.9.tar.gz (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 14.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.14.6)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.11.0)\n",
            "Collecting pyglet>=1.2.0 (from gym)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.0MB 18.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2018.10.15)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Running setup.py bdist_wheel for gym ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/6c/3a/0e/b86dee98876bb56cdb482cc1f72201035e46d1baf69d10d028\n",
            "Successfully built gym\n",
            "Installing collected packages: pyglet, gym\n",
            "Successfully installed gym-0.10.9 pyglet-1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AAUOnt4CUeLl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import transforms, utils, datasets\n",
        "import torchvision.models as models\n",
        "import os\n",
        "from IPython import display\n",
        "from itertools import chain\n",
        "from tqdm import tqdm\n",
        "from functools import reduce\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lzy4MCr2UKF8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        " \n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, inOpts, outOpts):\n",
        "      super(PolicyNetwork, self).__init__()\n",
        "      self.net=nn.Sequential(nn.Linear(inOpts, 10),\n",
        "                            nn.ReLU(), \n",
        "                            nn.Linear(10,10),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Linear(10,10),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Linear(10, outOpts))\n",
        "      self.softmax = nn.Softmax(dim=1)\n",
        "    \n",
        "    def forward(self, env, justProbs=False):\n",
        "      scores= self.net(env)\n",
        "      probs=self.softmax(scores)\n",
        "      if justProbs:\n",
        "        return probs\n",
        "      batch_size=env.shape[0]\n",
        "      actions = np.empty((batch_size,1), dtype=np.uint8)\n",
        "      probs_np = probs.cpu().detach().numpy()\n",
        "      for i in range(batch_size):\n",
        "        action_one_hot = np.random.multinomial(1, probs_np[i])\n",
        "        action_idx = np.argmax(action_one_hot)\n",
        "        actions[i,0] = action_idx\n",
        "      return(probs, actions)\n",
        " \n",
        "\n",
        "class ValueNetwork(nn.Module):\n",
        "    def __init__(self, num):\n",
        "      super(ValueNetwork, self).__init__()\n",
        "      self.net=nn.Sequential(\n",
        "      nn.Linear(4,10),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(10,10), \n",
        "      nn.ReLU(),\n",
        "      nn.Linear(10, 10),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(10,1))\n",
        "      \n",
        "    def forward(self, x):\n",
        "      return(self.net(x))\n",
        "      \n",
        "      \n",
        "      \n",
        "class AdvantageDataset(Dataset):                                                                                                                    \n",
        "    def __init__(self, experience):                                                                                                                 \n",
        "        super(AdvantageDataset, self).__init__()                                                                                                    \n",
        "        self._exp = experience                                                                                                                      \n",
        "        self._num_runs = len(experience)                                                                                                            \n",
        "        self._length = reduce(lambda acc, x: acc + len(x), experience, 0)                                                                           \n",
        " \n",
        "    def __getitem__(self, index):                                                                                                                   \n",
        "        idx = 0                                                                                                                                     \n",
        "        seen_data = 0                                                                                                                               \n",
        "        current_exp = self._exp[0]                                                                                                                  \n",
        "        while seen_data + len(current_exp) - 1 < index:                                                                                             \n",
        "            seen_data += len(current_exp)                                                                                                           \n",
        "            idx += 1                                                                                                                                \n",
        "            current_exp = self._exp[idx]                                                                                                            \n",
        "        chosen_exp = current_exp[index - seen_data]                                                                                                 \n",
        "        return chosen_exp[0], chosen_exp[4]                                                                                                         \n",
        " \n",
        "    def __len__(self):                                                                                                                              \n",
        "        return self._length                                                                                                                         \n",
        " \n",
        " \n",
        "class PolicyDataset(Dataset):                                                                                                                       \n",
        "    def __init__(self, experience):                                                                                                                 \n",
        "        super(PolicyDataset, self).__init__()                                                                                                       \n",
        "        self._exp = experience                                                                                                                      \n",
        "        self._num_runs = len(experience)                                                                                                            \n",
        "        self._length = reduce(lambda acc, x: acc + len(x), experience, 0)                                                                           \n",
        " \n",
        "    def __getitem__(self, index):                                                                                                                   \n",
        "        idx = 0                                                                                                                                     \n",
        "        seen_data = 0                                                                                                                               \n",
        "        current_exp = self._exp[0]                                                                                                                  \n",
        "        while seen_data + len(current_exp) - 1 < index:                                                                                             \n",
        "            seen_data += len(current_exp)                                                                                                           \n",
        "            idx += 1                                                                                                                                \n",
        "            current_exp = self._exp[idx]                                                                                                            \n",
        "        chosen_exp = current_exp[index - seen_data]                                                                                                 \n",
        "        return chosen_exp                                                                                                                           \n",
        " \n",
        "    def __len__(self):                                                                                                                              \n",
        "        return self._length                                                                                                                         \n",
        " \n",
        " \n",
        "def calc_returns(rollout, gamma):\n",
        "  current_return = 0\n",
        "  for i in reversed(range(len(rollout))):\n",
        "    state, action_dist, action, reward = rollout[i]\n",
        "    ret= reward+gamma*current_return\n",
        "    rollout[i] = (state, action_dist, action, reward, ret)\n",
        "    current_return = ret\n",
        "    \n",
        "def multinomial_likelihood(dist, idx):\n",
        "    return dist[range(dist.shape[0]), idx.long()[:, 0]].unsqueeze(1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AhXcHjHkVgJc",
        "colab_type": "code",
        "outputId": "90cfc309-bf39-477c-a241-a6831e338534",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "def main():\n",
        " \n",
        "    env = gym.make('CartPole-v0')\n",
        "    \n",
        "    policy = PolicyNetwork(4, 2)\n",
        "    value = ValueNetwork(4)\n",
        "    #Not sure why cuda isn't working, will come back to if necessary\n",
        "    #policy=policy.cuda()\n",
        "    #value=value.cuda()\n",
        "    params = chain(policy.parameters(), value.parameters())\n",
        "    optimizer = optim.Adam(params, lr= .001, betas = (.9, .999), weight_decay=.01)\n",
        "    value_criteria = nn.MSELoss()\n",
        "    \n",
        "    epsilon = .2\n",
        "    ppo_lb = 1-epsilon\n",
        "    ppo_ub = 1+epsilon\n",
        "    \n",
        "    epochs=25\n",
        "    policy_epochs = 5\n",
        "    num_rollouts = 100\n",
        "    max_ep_length= 200\n",
        "    gamma=.99\n",
        "    batch_size=256\n",
        "    val_losses=[]\n",
        "    policy_losses=[]\n",
        "    avg_reward=[]\n",
        "    \n",
        "    loop = tqdm(total=epochs, position = 0, leave=False)\n",
        "    \n",
        "    for e in range(epochs):\n",
        "      #print(e)\n",
        "      experiences=[]\n",
        "      rewards = []\n",
        "      for _ in range(num_rollouts):\n",
        "        current_rollout=[]\n",
        "        s = env.reset()\n",
        "        episode_reward=0\n",
        "        for b in range(max_ep_length):\n",
        "          state = torch.from_numpy(s).float().unsqueeze(0)\n",
        "          action_dist, action = policy(state)\n",
        "          action_dist, action = action_dist[0], action[0]\n",
        "          #print(action)\n",
        "          s_prime, r, t, _ = env.step(action.item())\n",
        "          current_rollout.append((s, action_dist.cpu().detach().numpy(), action, r))\n",
        "          episode_reward+=r\n",
        "          if t: \n",
        "            break\n",
        "          s=s_prime\n",
        "        calc_returns(current_rollout, gamma)\n",
        "        experiences.append(current_rollout)\n",
        "        rewards.append(episode_reward)\n",
        "      \n",
        "      #return(rewards)\n",
        "      #print(len(experiences))\n",
        "      #print(experiences)\n",
        "      avg_r = np.mean([x[0][4] for x in experiences])\n",
        "      #loop.set_description('average reward: % 6.2f' % (avg_r))\n",
        "      experience_dataset = PolicyDataset(experiences)\n",
        "      data_loader = DataLoader(experience_dataset, batch_size=batch_size,\n",
        "                                 shuffle=True,\n",
        "                                 pin_memory=True)\n",
        "      avg_policy_loss=0\n",
        "      avg_val_loss=0\n",
        "      for i in range(policy_epochs):\n",
        "        avg_policy_loss = 0\n",
        "        avg_val_loss = 0\n",
        "        for state, old_action_dist, old_action, reward, ret in data_loader:\n",
        "          #print(state.size(), old_action_dist.size(), old_action.size(), reward.size(), ret.size())\n",
        "          optimizer.zero_grad()\n",
        "          act_dist=policy(state.float(),True)\n",
        "          current_likelihood = multinomial_likelihood(act_dist, old_action)\n",
        "          old_likelihood = multinomial_likelihood(old_action_dist, old_action)\n",
        "          ratio = (current_likelihood / old_likelihood).squeeze(1)\n",
        "          \n",
        "          expected_returns = value(state.float())\n",
        "          val_loss = value_criteria(expected_returns.squeeze(1), ret.float())\n",
        "          #print(ret.size())\n",
        "          #print(expected_returns.squeeze(1).size())\n",
        "          advantage = ret.float() - expected_returns.squeeze(1)\n",
        "          #print(advantage.size())\n",
        "          #print(ratio.size())\n",
        "          #printaasfd\n",
        "          lhs = ratio * advantage\n",
        "          #print(lhs.size())\n",
        "          rhs = torch.clamp(ratio, ppo_lb, ppo_ub) * advantage\n",
        "          #print(rhs.size())\n",
        "          policy_loss = -torch.mean(torch.min(lhs, rhs))\n",
        "\n",
        "          # For logging\n",
        "          avg_val_loss += val_loss.item()\n",
        "          avg_policy_loss += policy_loss.item()\n",
        "          val_losses.append(val_loss.item())\n",
        "          policy_losses.append(policy_loss.item())\n",
        "\n",
        "          # Backpropagate\n",
        "          loss = policy_loss + val_loss\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "      avg_val_loss /= len(data_loader)\n",
        "      avg_policy_loss /= len(data_loader)\n",
        "      avg_reward.append(avg_r)\n",
        "      loop.set_description('avg reward: % 6.2f, value loss: % 6.2f, policy loss: % 6.2f' % (avg_r, avg_val_loss, avg_policy_loss))\n",
        "      loop.update(1)\n",
        "    return policy, value, val_losses, policy_losses, avg_reward\n",
        "            \n",
        "rewards=main()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
            "  result = entry_point.load(False)\n",
            "avg reward:  86.17, value loss:  293.32, policy loss:  -0.44: 100%|██████████| 25/25 [02:16<00:00,  7.48s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "JIUbGY5637ZT",
        "colab_type": "code",
        "outputId": "9dc83fdc-b33b-45e2-f878-acad1e6265b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "#print(rewards)\n",
        "#plt.plot(rewards[2])\n",
        "#plt.show()\n",
        "#plt.plot(rewards[3])\n",
        "#plt.show()\n",
        "plt.plot(rewards[4])\n",
        "plt.title(\"Average Reward\")\n",
        "plt.show()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3880bbe908>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "L8JDR_W31_zm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "    policy_optim = optim.Adam(policy.parameters(), lr=1e-2, weight_decay=0.01)\n",
        "    value_optim = optim.Adam(value.parameters(), lr=1e-3, weight_decay=1)\n",
        "    observation = env.reset()\n",
        "    print(observation)\n",
        "    for _ in range(1000):\n",
        "        #env.render()\n",
        "        action = env.action_space.sample() # your agent here (this takes random actions)\n",
        "        print(action)\n",
        "        observation, reward, done, info = env.step(action)\n",
        "        print(observation)\n",
        "        print(reward)\n",
        "        print(done)\n",
        "        print(info)\n",
        "\n",
        "    # ... more stuff here...\n",
        " \n",
        "    # Hyperparameters\n",
        "    epochs = 1000\n",
        "    env_samples = 100\n",
        "    episode_length = 200\n",
        "    gamma = 0.9\n",
        "    value_epochs = 2\n",
        "    policy_epochs = 5\n",
        "    batch_size = 32\n",
        "    policy_batch_size = 256\n",
        "    epsilon = 0.2\n",
        " \n",
        "    for _ in range(epochs):\n",
        "        # generate rollouts\n",
        "        rollouts = []\n",
        "        for _ in range(env_samples):\n",
        "            # don't forget to reset the environment at the beginning of each episode!\n",
        "            # rollout for a certain number of steps!\n",
        "            print(\"hi\")\n",
        " \n",
        "        print('avg standing time:', standing_len / env_samples)\n",
        "        calculate_returns(rollouts, gamma)\n",
        " \n",
        "        # Approximate the value function\n",
        "        value_dataset = AdvantageDataset(rollouts)\n",
        "        value_loader = DataLoader(value_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "        for _ in range(value_epochs):\n",
        "            # train value network\n",
        "            print(\"train value\")\n",
        " \n",
        "        calculate_advantages(rollouts, value)\n",
        " \n",
        "        # Learn a policy\n",
        "        policy_dataset = PolicyDataset(rollouts)\n",
        "        policy_loader = DataLoader(policy_dataset, batch_size=policy_batch_size, shuffle=True, pin_memory=True)\n",
        "        for _ in range(policy_epochs):\n",
        "            # train policy network\n",
        "            print(\"train policy\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}